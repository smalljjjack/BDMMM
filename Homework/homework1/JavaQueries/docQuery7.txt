1. Created a "Configuration" object to setup a job (JobForQuery7)
2. Check if appropriate command line arguments have been passed for the query as required, if not display error and exit the code.
3. Created Two Mapper Class (myPageQ7) and (AccessLogQ7) to join the DataSets to achieve the desired result.
4. Created One Reducer in "setNumReduceTasks" to 1.
5. Since the Input File is CSV, stored each value from the tuple in a String array. This method is followed in all the Mapper classes.
6. In mapper "myPageQ7" we pass the ID and the Name fields from the tuple.

7. In mapper "AccessLogQ5" we pass the "ByWho" field as key and AccessTime as the value for each tuple. This accesstime is required to gather all the accesstimes for the user. 

8. In the Reducer "IntSumReducer" we use a ArrayList to store all the values for AccessTime for the corresponding person based on the key, the we sort the access Times arrayList. 
9.For each tuple the differnce between the last element from the ArrayList and the first element in the arrayList is calculated, whcih is required to understand for how many days after starting the account the user used FaceBook.

10. Now we compare the date difference(between the first and last accesstime) to a standard number say "20000" indicating 2 months , we display all the user whose first access and last access is below the threshold set. 


Command: hadoop jar Query6.jar samp.Query6 'InputFileName1' 'InputFileName2' 'OutputFileName'
InputFileName1: MyPage.csv
InputFileName2: AccessLog.csv
